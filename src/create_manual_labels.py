"""
Script ƒë·ªÉ t·∫°o manual labels cho Lab 2 section 2.2.2

‚ö†Ô∏è Y√äU C·∫¶U QUAN TR·ªåNG t·ª´ text2.txt:
    "Manually label references for at least 5 publications"
    
Nghƒ©a l√†: Sinh vi√™n PH·∫¢I T·ª∞ TAY LABEL, kh√¥ng ƒë∆∞·ª£c d√πng automatic matching!

‚ö†Ô∏è Y√äU C·∫¶U B·ªî SUNG (t·ª´ h∆∞·ªõng d·∫´n Lab):
    - M·ªói publication MANUAL ph·∫£i c√≥ √≠t nh·∫•t 20 VALID matches
    - BibTeX entry kh√¥ng c√≥ match = INVALID (kh√¥ng t√≠nh v√†o s·ªë matches)
    - Publication c√≥ < 20 valid matches = INVALID sample (kh√¥ng ƒë∆∞·ª£c t√≠nh)
    - Auto labels cho ph√©p < 20 matches nh∆∞ng accuracy c√≥ th·ªÉ th·∫•p

Script n√†y h·ªó tr·ª£:
1. T√¨m publications c√≥ ƒë·ªß potential matches (‚â•20) ƒë·ªÉ label
2. Hi·ªÉn th·ªã BibTeX entries v√† candidates ƒë·ªÉ sinh vi√™n REVIEW
3. Sinh vi√™n t·ª± quy·∫øt ƒë·ªãnh match n√†o ƒë√∫ng
4. Validate: ch·ªâ save publication c√≥ ‚â•20 valid matches
5. L∆∞u k·∫øt qu·∫£ v√†o manual_labels.json

Format output theo y√™u c·∫ßu:
{
    "publication_id": {
        "bibtex_key": "arxiv_id",
        ...
    },
    ...
}
"""

import os
import sys
import json
import argparse
from pathlib import Path

# Set recursion limit before any library imports
sys.setrecursionlimit(10000)

# Add parent to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    # Disable pyparsing packrat to avoid recursion issues
    import pyparsing
    # For newer pyparsing versions, packrat is not enabled by default
    # Only disable if the method exists (older versions)
    if hasattr(pyparsing.ParserElement, 'disablePackrat'):
        pyparsing.ParserElement.disablePackrat()
except ImportError:
    pass

try:
    import bibtexparser
except ImportError:
    print("‚ùå bibtexparser not installed. Run: pip install bibtexparser")
    sys.exit(1)

try:
    from fuzzywuzzy import fuzz
except ImportError:
    print("‚ùå fuzzywuzzy not installed. Run: pip install fuzzywuzzy python-Levenshtein")
    sys.exit(1)


# ============================================================================
# CONSTANTS
# ============================================================================
MIN_VALID_MATCHES_MANUAL = 20  # M·ªói publication manual ph·∫£i c√≥ >= 20 valid matches
MIN_PUBLICATIONS_MANUAL = 5    # C·∫ßn √≠t nh·∫•t 5 publications cho manual labels
MIN_SCORE_AUTO_ACCEPT = 85     # Score t·ªëi thi·ªÉu ƒë·ªÉ auto-accept


# ============================================================================
# DATA LOADING FUNCTIONS
# ============================================================================
def load_refs_bib(path):
    """Load refs.bib file v√† tr·∫£ v·ªÅ dict {bib_key: entry}"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            bib_db = bibtexparser.load(f)
        return {entry['ID']: entry for entry in bib_db.entries}
    except Exception as e:
        return {}


def load_references_json(path):
    """Load references.json v√† tr·∫£ v·ªÅ dict {arxiv_id: metadata}
    
    Ch·ªâ tr·∫£ v·ªÅ nh·ªØng entry c√≥ metadata th·ª±c s·ª± (kh√¥ng r·ªóng)
    """
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # Filter: ch·ªâ gi·ªØ entries c√≥ data th·ª±c s·ª±
        # Use type().__name__ instead of isinstance() to avoid recursion issues
        valid_refs = {
            k: v for k, v in data.items() 
            if v and type(v).__name__ == 'dict' and len(v) > 0
        }
        return valid_refs
    except Exception as e:
        return {}


# ============================================================================
# CANDIDATE FINDING FUNCTIONS (adapted from 5paper_found.py)
# ============================================================================
def find_candidates_for_manual_labeling(output_dir, min_potential=20):
    """
    Qu√©t th∆∞ m·ª•c OUTPUT v√† t√¨m papers c√≥ ƒë·ªß potential matches ƒë·ªÉ manual labeling.
    
    ‚ö†Ô∏è Y√äU C·∫¶U: M·ªói paper manual PH·∫¢I c√≥ √≠t nh·∫•t 20 valid matches
    
    Ti√™u ch√≠:
    1. references.json PH·∫¢I c√≥ d·ªØ li·ªáu (ch·ª©a c√°c arXiv IDs ƒë·ªÉ match)
    2. refs.bib PH·∫¢I c√≥ entries (BibTeX entries t·ª´ paper)
    3. potential_matches = min(bib_count, arxiv_ref_count) >= min_potential
    
    Args:
        output_dir: Th∆∞ m·ª•c output ch·ª©a c√°c publication
        min_potential: S·ªë match ti·ªÅm nƒÉng t·ªëi thi·ªÉu (default=20 cho manual)
        
    Returns:
        list of candidate dicts sorted by potential (descending)
    """
    candidates = []
    
    output_path = Path(output_dir)
    if not output_path.exists():
        print(f"‚ùå Output directory kh√¥ng t·ªìn t·∫°i: {output_dir}")
        return []
    
    # L·∫•y danh s√°ch c√°c th∆∞ m·ª•c con (m·ªói th∆∞ m·ª•c l√† 1 paper)
    paper_dirs = [d for d in output_path.iterdir() if d.is_dir()]
    
    print(f"\nüîç ƒêang qu√©t {len(paper_dirs)} th∆∞ m·ª•c paper trong {output_dir}...")
    print("=" * 70)
    
    # Statistics
    stats = {
        'no_refs_json': 0,
        'empty_refs_json': 0,
        'no_refs_bib': 0,
        'empty_refs_bib': 0,
        'insufficient_potential': 0,
        'valid': 0
    }
    
    for paper_dir in paper_dirs:
        arxiv_id = paper_dir.name
        
        # 1. Ki·ªÉm tra references.json
        ref_json_path = paper_dir / 'references.json'
        if not ref_json_path.exists():
            stats['no_refs_json'] += 1
            continue
        
        refs_json_data = load_references_json(ref_json_path)
        if not refs_json_data:
            stats['empty_refs_json'] += 1
            continue
            
        # 2. Ki·ªÉm tra refs.bib
        refs_bib_path = paper_dir / 'refs.bib'
        if not refs_bib_path.exists():
            stats['no_refs_bib'] += 1
            continue
            
        bib_entries = load_refs_bib(refs_bib_path)
        if not bib_entries:
            stats['empty_refs_bib'] += 1
            continue
        
        # 3. T√≠nh s·ªë c·∫∑p match ti·ªÅm nƒÉng
        num_bib_entries = len(bib_entries)
        num_arxiv_refs = len(refs_json_data)
        potential_matches = min(num_bib_entries, num_arxiv_refs)
        
        # 4. Check minimum requirement
        if potential_matches < min_potential:
            stats['insufficient_potential'] += 1
            continue
        
        stats['valid'] += 1
        candidates.append({
            'pub_id': arxiv_id,
            'bib_count': num_bib_entries,
            'arxiv_refs_count': num_arxiv_refs,
            'potential_matches': potential_matches,
            'path': str(paper_dir),
            'sample_arxiv_ids': list(refs_json_data.keys())[:5]  # Preview
        })

    # Th·ªëng k√™
    print(f"\nüìä TH·ªêNG K√ä QU√âT:")
    print(f"   - T·ªïng s·ªë paper: {len(paper_dirs)}")
    print(f"   - Kh√¥ng c√≥ references.json: {stats['no_refs_json']}")
    print(f"   - references.json r·ªóng: {stats['empty_refs_json']}")
    print(f"   - Kh√¥ng c√≥ refs.bib: {stats['no_refs_bib']}")
    print(f"   - refs.bib r·ªóng: {stats['empty_refs_bib']}")
    print(f"   - Potential < {min_potential}: {stats['insufficient_potential']}")
    print(f"   - ‚úÖ Paper ƒë·ªß ƒëi·ªÅu ki·ªán (potential ‚â• {min_potential}): {stats['valid']}")
    
    if not candidates:
        print(f"\n‚ùå KH√îNG T√åM TH·∫§Y PAPER N√ÄO C√ì ‚â• {min_potential} POTENTIAL MATCHES!")
        print("   üí° G·ª£i √Ω:")
        print("   1. ƒê√£ ch·∫°y scraping metadata ƒë·ªÉ ƒëi·ªÅn references.json ch∆∞a?")
        print("   2. ƒê√£ ch·∫°y parser ƒë·ªÉ t·∫°o refs.bib ch∆∞a?")
        print("   3. Th·ª≠ gi·∫£m --min-matches n·∫øu c·∫ßn (cho auto labels)")
        return []

    # S·∫Øp x·∫øp theo potential matches (∆∞u ti√™n cao nh·∫•t)
    candidates.sort(key=lambda x: x['potential_matches'], reverse=True)
    
    return candidates


def display_top_candidates(candidates, num_display=10):
    """Hi·ªÉn th·ªã top candidates ƒë·ªÉ ch·ªçn labeling"""
    print("\n" + "=" * 70)
    print(f"üèÜ TOP {min(num_display, len(candidates))} PAPERS ƒê·ª¶ ƒêI·ªÄU KI·ªÜN CHO MANUAL LABELING")
    print(f"   (Y√™u c·∫ßu: m·ªói paper ph·∫£i c√≥ ‚â• {MIN_VALID_MATCHES_MANUAL} valid matches)")
    print("=" * 70)
    
    for i, c in enumerate(candidates[:num_display], 1):
        print(f"\n{i:2d}. Paper: {c['pub_id']}")
        print(f"    üìö BibTeX entries: {c['bib_count']}")
        print(f"    üîó arXiv references: {c['arxiv_refs_count']}")
        print(f"    ‚ú® Potential matches: {c['potential_matches']}")
    
    print("\n" + "=" * 70)


def analyze_single_paper(paper_dir):
    """Ph√¢n t√≠ch chi ti·∫øt m·ªôt paper c·ª• th·ªÉ"""
    paper_path = Path(paper_dir)
    
    print(f"\nüî¨ PH√ÇN T√çCH CHI TI·∫æT: {paper_path.name}")
    print("=" * 70)
    
    refs_json = {}
    bib_entries = {}
    
    # Load references.json
    ref_json_path = paper_path / 'references.json'
    if ref_json_path.exists():
        refs_json = load_references_json(ref_json_path)
        print(f"\nüìÑ references.json: {len(refs_json)} valid arXiv references")
        if refs_json:
            print("   Sample arXiv IDs c√≥ trong references.json:")
            for arxiv_id, metadata in list(refs_json.items())[:10]:
                title = metadata.get('title', metadata.get('paper_title', 'N/A'))
                if title and len(title) > 50:
                    title = title[:50] + '...'
                print(f"   - {arxiv_id}: {title}")
            if len(refs_json) > 10:
                print(f"   ... v√† {len(refs_json) - 10} arXiv IDs kh√°c")
    else:
        print("\n‚ùå Kh√¥ng t√¨m th·∫•y references.json")
    
    # Load refs.bib
    refs_bib_path = paper_path / 'refs.bib'
    if refs_bib_path.exists():
        bib_entries = load_refs_bib(refs_bib_path)
        print(f"\nüìÑ refs.bib: {len(bib_entries)} BibTeX entries")
        if bib_entries:
            print("   Sample BibTeX keys:")
            for bib_key, entry in list(bib_entries.items())[:10]:
                title = entry.get('title', 'N/A')
                if title and len(title) > 40:
                    title = title[:40] + '...'
                print(f"   - {bib_key}: {title}")
            if len(bib_entries) > 10:
                print(f"   ... v√† {len(bib_entries) - 10} entries kh√°c")
    else:
        print("\n‚ùå Kh√¥ng t√¨m th·∫•y refs.bib")
    
    return refs_json, bib_entries


# ============================================================================
# MATCHING FUNCTIONS
# ============================================================================
def calculate_match_score(bib_entry, ref_data):
    """
    T√≠nh ƒëi·ªÉm match gi·ªØa m·ªôt BibTeX entry v√† m·ªôt reference t·ª´ references.json
    
    Returns:
        tuple (score, details)
    """
    bib_title = bib_entry.get('title', '').lower().strip()
    ref_title = ref_data.get('paper_title', ref_data.get('title', '')).lower().strip()
    
    bib_authors = bib_entry.get('author', bib_entry.get('authors', '')).lower()
    ref_authors = ref_data.get('paper_authors', ref_data.get('authors', ''))
    
    # Use type().__name__ instead of isinstance() to avoid recursion issues
    if type(ref_authors).__name__ in ('list', 'tuple'):
        ref_authors = ' '.join(str(a) for a in ref_authors).lower()
    else:
        ref_authors = str(ref_authors).lower()
    
    # Title similarity (most important)
    title_score = fuzz.token_sort_ratio(bib_title, ref_title) if bib_title and ref_title else 0
    
    # Author overlap
    author_score = fuzz.token_set_ratio(bib_authors, ref_authors) if bib_authors and ref_authors else 0
    
    # Combined score
    combined_score = title_score * 0.7 + author_score * 0.3
    
    return combined_score, {
        'title_score': title_score,
        'author_score': author_score,
        'bib_title': bib_title[:60] + '...' if len(bib_title) > 60 else bib_title,
        'ref_title': ref_title[:60] + '...' if len(ref_title) > 60 else ref_title
    }


def find_best_matches(refs_bib, references, top_n=3):
    """
    T√¨m best matches cho m·ªói BibTeX entry
    
    Returns:
        dict of {bibtex_key: [(arxiv_id, score, details), ...]}
    """
    matches = {}
    
    for bib_key, bib_entry in refs_bib.items():
        candidates = []
        
        for arxiv_id, ref_data in references.items():
            if not ref_data:  # Skip empty entries
                continue
                
            score, details = calculate_match_score(bib_entry, ref_data)
            candidates.append((arxiv_id, score, details))
        
        # Sort by score descending
        candidates.sort(key=lambda x: x[1], reverse=True)
        
        # Keep top N
        matches[bib_key] = candidates[:top_n]
    
    return matches


# ============================================================================
# INTERACTIVE LABELING
# ============================================================================
def interactive_labeling(output_dir, pub_id, min_matches=20, auto_mode=False):
    """
    Interactive MANUAL labeling cho m·ªôt publication
    
    ‚ö†Ô∏è Y√äU C·∫¶U: 
    - Sinh vi√™n ph·∫£i T·ª∞ TAY x√°c nh·∫≠n t·ª´ng match
    - Publication MANUAL ph·∫£i c√≥ ‚â• min_matches valid matches
    - BibTeX entry kh√¥ng match = INVALID (kh√¥ng t√≠nh)
    
    Args:
        output_dir: Th∆∞ m·ª•c output
        pub_id: Publication ID
        min_matches: S·ªë valid matches t·ªëi thi·ªÉu ƒë·ªÉ publication ƒë∆∞·ª£c t√≠nh
        auto_mode: False = manual confirm, True = auto-accept high scores
    
    Returns:
        tuple (labels_dict, stats_dict)
            - labels_dict: {bibtex_key: arxiv_id} cho c√°c valid matches
            - stats_dict: th·ªëng k√™ v·ªÅ valid/invalid entries
    """
    pub_path = Path(output_dir) / pub_id
    refs_bib_path = pub_path / 'refs.bib'
    references_path = pub_path / 'references.json'
    
    if not refs_bib_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y refs.bib t·∫°i {refs_bib_path}")
        return {}, {'error': 'no_refs_bib'}
    
    if not references_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y references.json t·∫°i {references_path}")
        return {}, {'error': 'no_references_json'}
    
    refs_bib = load_refs_bib(refs_bib_path)
    references = load_references_json(references_path)
    
    print(f"\n{'='*70}")
    print(f"MANUAL LABELING PUBLICATION: {pub_id}")
    print(f"{'='*70}")
    print(f"üìä BibTeX entries: {len(refs_bib)}")
    print(f"üìä arXiv references (valid): {len(references)}")
    print(f"üìä Potential matches: {min(len(refs_bib), len(references))}")
    print(f"‚ö†Ô∏è  Y√™u c·∫ßu: ‚â• {min_matches} valid matches ƒë·ªÉ publication ƒë∆∞·ª£c t√≠nh")
    
    # Find best matches
    matches = find_best_matches(refs_bib, references)
    
    # Statistics
    stats = {
        'total_bib_entries': len(refs_bib),
        'total_arxiv_refs': len(references),
        'valid_matches': 0,
        'invalid_entries': 0,  # BibTeX entries kh√¥ng c√≥ match
        'skipped_entries': 0,   # User skipped manually
    }
    
    labels = {}
    
    if auto_mode:
        print("\n‚ö†Ô∏è WARNING: AUTO MODE - CH·ªà ƒê·ªÇ TEST!")
        print("Y√™u c·∫ßu th·∫≠t s·ª±: Ph·∫£i MANUAL REVIEW t·ª´ng pair")
    
    print("\n" + "-"*70)
    print("H∆Ø·ªöNG D·∫™N:")
    print("- H·ªá th·ªëng hi·ªÉn th·ªã BibTeX entry v√† top 3 candidates")
    print("- B·∫†N xem x√©t v√† quy·∫øt ƒë·ªãnh match n√†o ƒë√∫ng")
    print("- BibTeX entry KH√îNG C√ì MATCH s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u INVALID")
    print("- KH√îNG t√≠nh v√†o s·ªë valid matches")
    if not auto_mode:
        print("- Nh·∫≠p s·ªë th·ª© t·ª± (1-3) ƒë·ªÉ ch·ªçn match")
        print("- Nh·∫≠p 'n' ƒë·ªÉ ƒë√°nh d·∫•u KH√îNG C√ì MATCH (invalid entry)")
        print("- Nh·∫≠p 'q' ƒë·ªÉ d·ª´ng labeling publication n√†y")
    print("-"*70)
    
    processed = 0
    for bib_key, candidates in matches.items():
        processed += 1
        bib_entry = refs_bib[bib_key]
        bib_title = bib_entry.get('title', 'N/A')
        bib_author = bib_entry.get('author', 'N/A')
        
        print(f"\n{'‚îÄ'*70}")
        print(f"[{processed}/{len(refs_bib)}] üìö BibTeX Entry: {bib_key}")
        print(f"   Title: {bib_title}")
        print(f"   Author: {str(bib_author)[:100]}...")
        print(f"   ‚úÖ Valid matches so far: {stats['valid_matches']} / {min_matches} required")
        
        # Check if any candidate exists
        valid_candidates = [c for c in candidates if c[1] > 0]  # Score > 0
        
        if not valid_candidates:
            print("   ‚ö†Ô∏è KH√îNG C√ì CANDIDATE N√ÄO!")
            print("   ‚Üí Entry n√†y s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u INVALID (kh√¥ng t√≠nh v√†o matches)")
            stats['invalid_entries'] += 1
            continue
        
        print(f"\n   Top {len(valid_candidates[:3])} candidates:")
        for i, (arxiv_id, score, details) in enumerate(valid_candidates[:3], 1):
            ref_data = references.get(arxiv_id, {})
            ref_title = ref_data.get('paper_title', ref_data.get('title', 'N/A'))
            ref_authors = ref_data.get('paper_authors', ref_data.get('authors', ''))
            if type(ref_authors).__name__ in ('list', 'tuple'):
                ref_authors = ', '.join(str(a) for a in ref_authors)
            
            print(f"\n   [{i}] arxiv_id: {arxiv_id}")
            print(f"       Title: {str(ref_title)[:80]}...")
            print(f"       Authors: {str(ref_authors)[:60]}...")
            print(f"       Score: {score:.1f} (title={details['title_score']}, author={details['author_score']})")
        
        # Decision making
        if auto_mode:
            # Auto mode: accept score >= MIN_SCORE_AUTO_ACCEPT
            best_arxiv_id, best_score, _ = valid_candidates[0]
            if best_score >= MIN_SCORE_AUTO_ACCEPT:
                labels[bib_key] = best_arxiv_id
                stats['valid_matches'] += 1
                print(f"\n   ‚úÖ AUTO-SELECTED (score={best_score:.0f}): {best_arxiv_id}")
            else:
                stats['invalid_entries'] += 1
                print(f"   ‚ùå INVALID (score too low: {best_score:.0f} < {MIN_SCORE_AUTO_ACCEPT})")
        else:
            # MANUAL MODE
            while True:
                try:
                    choice = input(f"\n   üëâ Ch·ªçn (1-{len(valid_candidates[:3])}) | 'n'=no match (invalid) | 'q'=quit: ").strip().lower()
                except EOFError:
                    # Non-interactive mode
                    stats['skipped_entries'] += 1
                    break
                
                if choice == 'q':
                    print("\n   ‚è∏Ô∏è D·ª´ng labeling publication n√†y")
                    # Return what we have
                    return labels, stats
                elif choice == 'n':
                    stats['invalid_entries'] += 1
                    print("   ‚ùå ƒê√°nh d·∫•u INVALID - entry n√†y kh√¥ng c√≥ match")
                    break
                elif choice.isdigit():
                    idx = int(choice) - 1
                    if 0 <= idx < len(valid_candidates[:3]):
                        selected_id = valid_candidates[idx][0]
                        labels[bib_key] = selected_id
                        stats['valid_matches'] += 1
                        print(f"   ‚úÖ ƒê√£ ch·ªçn: {selected_id}")
                        break
                    else:
                        print(f"   ‚ùå S·ªë kh√¥ng h·ª£p l·ªá, nh·∫≠p 1-{len(valid_candidates[:3])}")
                else:
                    print("   ‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
    
    return labels, stats


# ============================================================================
# MAIN LABELING WORKFLOW
# ============================================================================
def create_manual_labels_interactive(output_dir, num_pubs=5, min_matches=20, 
                                     auto_mode=False, show_candidates=True):
    """
    T·∫°o manual labels cho publications
    
    ‚ö†Ô∏è Y√äU C·∫¶U MANUAL LABELS:
    - M·ªói publication PH·∫¢I c√≥ ‚â• min_matches valid matches
    - Publication c√≥ < min_matches valid matches = INVALID (kh√¥ng ƒë∆∞·ª£c t√≠nh)
    - C·∫ßn √≠t nh·∫•t num_pubs valid publications
    
    Args:
        output_dir: Th∆∞ m·ª•c output ch·ª©a c√°c publication
        num_pubs: S·ªë publication c·∫ßn label (m·∫∑c ƒë·ªãnh 5)
        min_matches: S·ªë valid matches t·ªëi thi·ªÉu m·ªói publication (m·∫∑c ƒë·ªãnh 20)
        auto_mode: False = manual confirm, True = auto (CH·ªà TEST)
        show_candidates: Hi·ªÉn th·ªã danh s√°ch candidates tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
    
    Returns:
        dict: manual_labels theo format y√™u c·∫ßu
    """
    # Step 1: Find candidates with enough potential
    candidates = find_candidates_for_manual_labeling(output_dir, min_potential=min_matches)
    
    if not candidates:
        return {}
    
    if show_candidates:
        display_top_candidates(candidates, num_display=15)
    
    # Check if we have enough candidates
    if len(candidates) < num_pubs:
        print(f"\n‚ö†Ô∏è CH·ªà C√ì {len(candidates)} papers ƒë·ªß ƒëi·ªÅu ki·ªán, c·∫ßn {num_pubs}")
        print("   Ti·∫øp t·ª•c v·ªõi s·ªë papers hi·ªán c√≥...")
    
    if auto_mode:
        print("\n" + "="*70)
        print("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: AUTO MODE ENABLED ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
        print("Ch·∫ø ƒë·ªô n√†y CH·ªà ƒê·ªÇ TEST - KH√îNG h·ª£p l·ªá cho submission!")
        print("Y√™u c·∫ßu th·∫≠t s·ª±: 'Manually label references'")
        print("="*70 + "\n")
    
    # Step 2: Interactive labeling
    manual_labels = {}
    valid_publications = 0
    invalid_publications = 0
    total_valid_matches = 0
    
    pub_index = 0
    while valid_publications < num_pubs and pub_index < len(candidates):
        candidate = candidates[pub_index]
        pub_id = candidate['pub_id']
        pub_index += 1
        
        print(f"\n{'='*70}")
        print(f"üìñ Publication {valid_publications + 1}/{num_pubs}: {pub_id}")
        print(f"   (Candidate {pub_index}/{len(candidates)})")
        print(f"{'='*70}")
        
        labels, stats = interactive_labeling(output_dir, pub_id, 
                                              min_matches=min_matches,
                                              auto_mode=auto_mode)
        
        # Validate: publication ph·∫£i c√≥ >= min_matches valid matches
        if labels and len(labels) >= min_matches:
            manual_labels[pub_id] = labels
            valid_publications += 1
            total_valid_matches += len(labels)
            print(f"\n‚úÖ VALID PUBLICATION!")
            print(f"   Valid matches: {len(labels)} (‚â• {min_matches} ‚úì)")
            print(f"   Invalid entries: {stats.get('invalid_entries', 0)}")
        else:
            invalid_publications += 1
            print(f"\n‚ùå INVALID PUBLICATION!")
            print(f"   Valid matches: {len(labels)} (< {min_matches} required)")
            print(f"   Invalid entries: {stats.get('invalid_entries', 0)}")
            print(f"   ‚Üí Publication n√†y KH√îNG ƒë∆∞·ª£c t√≠nh v√†o manual labels")
            
            if pub_index < len(candidates):
                print(f"   ‚Üí Chuy·ªÉn sang paper ti·∫øp theo...")
            else:
                print(f"   ‚ö†Ô∏è H·∫øt candidates ƒë·ªÉ ch·ªçn!")
    
    # Step 3: Final summary
    print(f"\n{'='*70}")
    print("üìä FINAL SUMMARY")
    print("="*70)
    print(f"   Valid publications: {valid_publications}/{num_pubs} required")
    print(f"   Invalid publications (< {min_matches} matches): {invalid_publications}")
    print(f"   Total valid matches: {total_valid_matches}")
    print(f"   Average matches/pub: {total_valid_matches/valid_publications:.1f}" if valid_publications > 0 else "   Average: N/A")
    
    # Validate requirements
    print(f"\n{'‚îÄ'*70}")
    print("üìã REQUIREMENTS CHECK:")
    
    req_pubs = valid_publications >= MIN_PUBLICATIONS_MANUAL
    req_matches = all(len(v) >= MIN_VALID_MATCHES_MANUAL for v in manual_labels.values())
    
    print(f"   [{'‚úÖ' if req_pubs else '‚ùå'}] ‚â• {MIN_PUBLICATIONS_MANUAL} valid publications: {valid_publications}")
    print(f"   [{'‚úÖ' if req_matches else '‚ùå'}] Each pub has ‚â• {MIN_VALID_MATCHES_MANUAL} valid matches")
    
    if req_pubs and req_matches:
        print(f"\nüéâ ALL REQUIREMENTS MET!")
    else:
        print(f"\n‚ö†Ô∏è REQUIREMENTS NOT MET")
        if not req_pubs:
            print(f"   Need {MIN_PUBLICATIONS_MANUAL - valid_publications} more valid publications")
    
    print("="*70)
    
    return manual_labels


def save_manual_labels(labels, output_path):
    """Save manual labels to JSON file
    
    C≈©ng in ra statistics v·ªÅ labels
    """
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(labels, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ Saved manual labels to {output_path}")
    print(f"   Publications: {len(labels)}")
    
    total_pairs = sum(len(v) for v in labels.values())
    print(f"   Total pairs: {total_pairs}")
    
    # Per-publication breakdown
    print(f"\n   Per-publication breakdown:")
    for pub_id, matches in labels.items():
        status = "‚úÖ" if len(matches) >= MIN_VALID_MATCHES_MANUAL else "‚ö†Ô∏è"
        print(f"   {status} {pub_id}: {len(matches)} matches")


def load_existing_labels(path):
    """Load existing manual labels ƒë·ªÉ c√≥ th·ªÉ ti·∫øp t·ª•c labeling"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except Exception as e:
        print(f"‚ö†Ô∏è Error loading existing labels: {e}")
        return {}


# ============================================================================
# MAIN
# ============================================================================
def main():
    parser = argparse.ArgumentParser(
        description='Create MANUAL labels for Lab 2 (Requirement 2.2.2)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‚ö†Ô∏è Y√äU C·∫¶U QUAN TR·ªåNG (t·ª´ h∆∞·ªõng d·∫´n Lab):
    1. M·ªói publication MANUAL ph·∫£i c√≥ √≠t nh·∫•t 20 VALID matches
    2. BibTeX entry kh√¥ng c√≥ match = INVALID (kh√¥ng t√≠nh v√†o s·ªë matches)
    3. Publication c√≥ < 20 valid matches = INVALID sample
    4. C·∫ßn √≠t nh·∫•t 5 valid publications
    
    --auto ch·ªâ ƒë·ªÉ TEST nhanh, KH√îNG ƒë∆∞·ª£c d√πng cho submission!

Examples:
    # Manual labeling (recommended)
    python create_manual_labels.py --output-dir ../output
    
    # Scan only - kh√¥ng label, ch·ªâ t√¨m candidates
    python create_manual_labels.py --output-dir ../output --scan-only
    
    # Auto mode for testing (NOT for submission)
    python create_manual_labels.py --output-dir ../output --auto
        """
    )
    parser.add_argument('--output-dir', default='../output', 
                       help='Output directory with publications')
    parser.add_argument('--num-pubs', type=int, default=5, 
                       help='Number of valid publications needed (default: 5)')
    parser.add_argument('--min-matches', type=int, default=20, 
                       help='Minimum valid matches per publication (default: 20)')
    parser.add_argument('--save-to', default='manual_labels.json', 
                       help='Output file path')
    parser.add_argument('--auto', action='store_true',
                       help='‚ö†Ô∏è AUTO MODE - CH·ªà ƒê·ªÇ TEST!')
    parser.add_argument('--scan-only', action='store_true',
                       help='Ch·ªâ scan v√† hi·ªÉn th·ªã candidates, kh√¥ng labeling')
    parser.add_argument('--analyze', type=str, default=None,
                       help='Analyze a specific publication (pub_id)')
    
    args = parser.parse_args()
    
    print("="*70)
    print("üìù MANUAL LABELING TOOL - Lab 2 Section 2.2.2")
    print("="*70)
    print(f"Requirements:")
    print(f"   - ‚â• {args.num_pubs} valid publications")
    print(f"   - Each publication: ‚â• {args.min_matches} valid matches")
    print(f"   - BibTeX entries without match = INVALID")
    print("="*70)
    
    # Mode: Analyze single publication
    if args.analyze:
        pub_path = Path(args.output_dir) / args.analyze
        if pub_path.exists():
            analyze_single_paper(pub_path)
        else:
            print(f"‚ùå Publication kh√¥ng t·ªìn t·∫°i: {args.analyze}")
        return
    
    # Mode: Scan only
    if args.scan_only:
        candidates = find_candidates_for_manual_labeling(
            args.output_dir, 
            min_potential=args.min_matches
        )
        if candidates:
            display_top_candidates(candidates, num_display=20)
        return
    
    # Mode: Auto labeling (TEST ONLY)
    if args.auto:
        print("\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è AUTO MODE - CH·ªà ƒê·ªÇ TEST ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
        try:
            confirm = input("B·∫°n hi·ªÉu r·∫±ng auto mode KH√îNG h·ª£p l·ªá cho submission? (yes/no): ")
            if confirm.lower() != 'yes':
                print("ƒê√£ h·ªßy.")
                return
        except EOFError:
            pass  # Non-interactive mode, proceed
    
    # Mode: Manual labeling (default)
    labels = create_manual_labels_interactive(
        args.output_dir, 
        num_pubs=args.num_pubs,
        min_matches=args.min_matches,
        auto_mode=args.auto
    )
    
    # Save results
    if labels:
        save_manual_labels(labels, args.save_to)
        
        # Final validation
        valid_count = sum(1 for v in labels.values() if len(v) >= args.min_matches)
        if valid_count >= args.num_pubs:
            print(f"\nüéâ SUCCESS! Manual labels file is ready for evaluation")
        else:
            print(f"\n‚ö†Ô∏è WARNING: Only {valid_count}/{args.num_pubs} valid publications")
            print("   Consider adding more labels")
    else:
        print("\n‚ùå No valid labels created!")
        print("   Please try again with different publications")


if __name__ == "__main__":
    main()
