# Lab 2: Introduction to Data Science
**Student ID**: 23120067

## ğŸ“‹ Project Overview

This project implements a complete pipeline for:
1. **Hierarchical LaTeX Parsing**: Convert raw LaTeX sources into structured JSON format
2. **Reference Matching**: Use machine learning to match BibTeX entries with arXiv references

## ğŸ—ï¸ Project Structure
```
23120067/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser/              # LaTeX parsing modules
â”‚   â”œâ”€â”€ matcher/             # ML matching modules
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ main_parser.py       # Run parser
â”‚   â””â”€â”€ main_matcher.py      # Run ML pipeline
â”œâ”€â”€ notebooks/               # Jupyter notebooks (optional)
â”œâ”€â”€ tests/                   # Unit tests (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ Report.pdf
```

## ğŸš€ Quick Start

### 1. Environment Setup
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r src/requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Download SpaCy model (if using SpaCy)
python -m spacy download en_core_web_sm
```

### 2. Run Parser
```bash
# Parse all publications
python src/main_parser.py \
    --input-dir ./23120067 \
    --output-dir ./output

# Parse single publication
python src/main_parser.py \
    --input-dir ./23120067/2504-13946 \
    --output-dir ./output/2504-13946
```

**Expected Output**:
- `hierarchy.json`: Hierarchical structure
- `refs.bib`: Unified BibTeX file
- Logs in console

### 3. Run ML Pipeline
```bash
# Train and evaluate
python src/main_matcher.py \
    --data-dir ./23120067 \
    --output-dir ./output \
    --model-type ranker

# Options:
#   --model-type: 'classifier' or 'ranker' (default: ranker)
```

**Expected Output**:
- Trained model: `output/model.cbm`
- Predictions: `<pub-id>/pred.json` for each test publication
- MRR score in console

## ğŸ“Š Data Format

### Input Structure (from Lab 1)
```
23120067/
â”œâ”€â”€ 2504-13946/
â”‚   â”œâ”€â”€ metadata.json
â”‚   â”œâ”€â”€ references.json
â”‚   â””â”€â”€ tex/
â”‚       â”œâ”€â”€ 2504-13946v1/
â”‚       â”‚   â”œâ”€â”€ main.tex
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ 2504-13946v2/
â”‚           â””â”€â”€ ...
â””â”€â”€ ...
```

### Output Structure
```
23120067/
â”œâ”€â”€ 2504-13946/
â”‚   â”œâ”€â”€ hierarchy.json    â† NEW
â”‚   â”œâ”€â”€ refs.bib          â† NEW
â”‚   â”œâ”€â”€ metadata.json
â”‚   â”œâ”€â”€ references.json
â”‚   â””â”€â”€ pred.json         â† NEW (if used for ML)
â””â”€â”€ ...
```

## ğŸ”§ Configuration

Edit `src/config.py` to customize:
- Student ID
- Model parameters
- Feature thresholds
- Data split ratios

Example:
```python
STUDENT_ID = "23120067"
MODEL_TYPE = 'ranker'
CATBOOST_PARAMS = {
    'iterations': 200,
    'learning_rate': 0.1,
    'depth': 6
}
```

## ğŸ“ˆ Features Used

### Traditional Features
- Title similarity (Jaccard, Levenshtein, TF-IDF cosine)
- Author matching (overlap ratio, first/last author)
- Year difference
- Text embeddings (optional)

### Hierarchy-Based Features (NEW!)
- Citation frequency
- Citation sections (intro/methods/results)
- Citation depth in hierarchy
- Proximity to figures/tables
- Co-citation patterns

## ğŸ¯ Model Performance

| Metric | Score |
|--------|-------|
| MRR    | 0.XXX |
| Hit@1  | X.XX% |
| Hit@3  | X.XX% |
| Hit@5  | X.XX% |

*(Fill in after running evaluation)*

## ğŸ› Troubleshooting

### Issue 1: TexSoup parsing errors
**Solution**: Check for malformed LaTeX commands. Add error handling in `hierarchy_builder.py`

### Issue 2: Memory error during feature extraction
**Solution**: Process publications in batches. Reduce TF-IDF max_features in `config.py`

### Issue 3: CatBoost installation fails
**Solution**: 
```bash
# Try with conda
conda install -c conda-forge catboost

# Or build from source
pip install catboost --no-binary catboost
```

## ğŸ“š Key Implementation Details

### 1. Reference Deduplication with Citation Renaming
The deduplicator finds duplicate references and automatically renames all `\cite{}` commands:
```python
# Before
\cite{lipton2018interpretability}
\cite{lipton2018mythos}

# After (both refer to same entry)
\cite{lipton2018mythos}
\cite{lipton2018mythos}
```

### 2. Itemize as Branching Structure
Itemize blocks are parsed as hierarchical elements:
```latex
\begin{itemize}
    \item First point
    \item Second point
\end{itemize}
```

Becomes:
```
itemize-block-1 (parent)
  â”œâ”€â”€ item-1 (child)
  â””â”€â”€ item-2 (child)
```

### 3. mÃ—n Pairs Generation
For each publication with m BibTeX entries and n candidates, we create mÃ—n pairs:
```python
# Example: 10 BibTeX Ã— 50 candidates = 500 pairs
pairs = [
    (bibtex_1, candidate_1),
    (bibtex_1, candidate_2),
    ...
    (bibtex_10, candidate_50)
]
```

## ğŸ¥ Demonstration Video

**Link**: [YouTube Video](https://youtube.com/...)

**Contents**:
- Environment setup
- Running parser
- Running ML pipeline
- Results visualization

**Duration**: 4-5 minutes

## ğŸ“ Report

See `Report.pdf` for detailed explanation of:
- Implementation approach
- Feature engineering rationale
- Model selection justification
- Results analysis
- Statistics and insights

## ğŸ“§ Contact

**Student**: [Your Name]  
**Student ID**: 23120067  
**Email**: [your-email]

For questions about this implementation, please contact the instructor:
- **Huá»³nh LÃ¢m Háº£i ÄÄƒng**: hlhdang@fit.hcmus.edu.vn

## ğŸ™ Acknowledgments

- LaTeX parsing: TexSoup library
- Machine Learning: CatBoost
- Text processing: NLTK, scikit-learn
- Data from: arXiv, Semantic Scholar API

## ğŸ“„ License

This project is for educational purposes only.